[["index.html", "eBird Status Data Products Workshop Welcome 0.1 Setup", " eBird Status Data Products Workshop Matt Strimas-Mackey and Tom Auer Welcome The community science project eBird has generated a database of over 1 billion bird observations, with broad spatial and taxonomic coverage. Over the past 10 years, the Cornell Lab of Ornithology has developed machine-learning models using eBird and remotely-sensed data to produce high resolution, weekly estimates of range boundaries, occurrence rate, and relative abundance while accounting for many of the biases inherent in community science datasets, including variation in observer behavior and effort. Visualizations and modeled Data Products over 800 bird species are currently available through the eBird Status and Trends website. This workshop will introduce attendees to the eBird Status Data Products (weekly estimates of range boundaries, occurrence rate, relative abundance, and habitat associations) and the ebirdst R package developed specifically for working with these data. This will include an introduction to the modeling process used to generate the eBird Status Data Products. It will also include a demonstration of how to access and manipulate these Data Products for specific combinations of species, seasons, and regions using the ebirdst package. After the workshop, attendees will have an understanding of how and when to use these Data Products for applied research and conservation efforts, including within-year dynamics. Some experience with R is required to follow along with the lessons in this workshop. Please note, this workshop will not cover the analysis of trends or trend data. 0.1 Setup To run the code in the workshop you’ll need to install the following packages: install.packages(c(&quot;tidyverse&quot;, &quot;raster&quot;, &quot;sf&quot;, &quot;rnaturalearth&quot;, &quot;rgeos&quot;, &quot;remotes&quot;, &quot;exactextractr&quot;)) remotes::install_github(&quot;ropensci/rnaturalearthhires&quot;) You’ll also need to install the latest version of the ebirdst R package from GitHub: remotes::install_github(&quot;CornellLabofOrnithology/ebirdst&quot;) To download the source files and following along with this workshop visit the GitHub repository. "],["access.html", "Lesson 1 Data Access 1.1 Objective 1.2 Introduction 1.3 Request access 1.4 Species list 1.5 Download data 1.6 Load data 1.7 Mapping", " Lesson 1 Data Access 1.1 Objective To download eBird Status &amp; Trends data using the R package ebirdst, load those data into R and make a simple map. 1.2 Introduction eBird Status and Trends provides modeled estimates of the distributions, relative abundances, and environmental associations for more than 800 bird species over their full annual cycle at high spatial and temporal resolution. The data behind the visualizations and maps you’ve likely seen online are referred to as the eBird Status Data Products, and are available for download for most academic and research uses. The R package ebirdst has been specifically designed to help download, manipulate, and analyze these data. Let’s start by loading the ebirdst R package and some additional packages for working with the data. library(ebirdst) library(raster) library(dplyr) 1.3 Request access As of July 2021, access to the eBird Status Data Products is now granted through an Access Request Form at: https://ebird.org/st/request. Access with this form generates a key to be used with the ebirdst R package and is provided immediately (as long as commercial use is not requested). Our terms of use have been updated to be more permissive in many cases, particularly academic and research use. When requesting data access, please be sure to carefully read the terms of use and ensure that your intended use is not restricted. After reading the eBird Status and Trends Products Terms of Use and filling out the Access Request Form you will be provided with an alphanumeric access key. To store the access key so it can be accessed by R and the ebirdst package, run the following (replacing \"XXXXXXXXX\" with your actual key): set_ebirdst_access_key(&quot;XXXXXXXXX&quot;) Then immediately restart R. This will save the access key as the environment variable EBIRDST_KEY in your .Renviron file so it’s accessible within your R session. 1.4 Species list The ebirdst_runs object is a data frame listing all the available species. glimpse(ebirdst_runs) #&gt; Rows: 807 #&gt; Columns: 20 #&gt; $ run_name &lt;chr&gt; &quot;pabtin1-ERD2019-STATUS-20200828-baf1cd73&quot;, &quot;bbwduc-ERD2019-STATUS-2020100… #&gt; $ species_code &lt;chr&gt; &quot;pabtin1&quot;, &quot;bbwduc&quot;, &quot;wiwduc1&quot;, &quot;fuwduc&quot;, &quot;empgoo&quot;, &quot;snogoo&quot;, &quot;rosgoo&quot;, &quot;g… #&gt; $ scientific_name &lt;chr&gt; &quot;Crypturellus transfasciatus&quot;, &quot;Dendrocygna autumnalis&quot;, &quot;Dendrocygna arbo… #&gt; $ common_name &lt;chr&gt; &quot;Pale-browed Tinamou&quot;, &quot;Black-bellied Whistling-Duck&quot;, &quot;West Indian Whistl… #&gt; $ resident &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,… #&gt; $ breeding_quality &lt;dbl&gt; 2, 3, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3,… #&gt; $ breeding_start &lt;date&gt; NA, 2019-05-24, NA, 2019-05-10, 2019-05-24, 2019-06-07, 2019-06-07, 2019-… #&gt; $ breeding_end &lt;date&gt; NA, 2019-08-03, NA, 2019-08-17, 2019-06-21, 2019-08-03, 2019-06-28, 2019-… #&gt; $ nonbreeding_quality &lt;dbl&gt; 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,… #&gt; $ nonbreeding_start &lt;date&gt; NA, 2019-01-18, NA, 2019-11-30, 2019-10-26, 2019-12-28, 2019-12-21, 2019-… #&gt; $ nonbreeding_end &lt;date&gt; NA, 2019-03-01, NA, 2019-02-15, 2019-04-05, 2019-01-11, 2019-01-11, 2019-… #&gt; $ postbreeding_migration_quality &lt;dbl&gt; 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3,… #&gt; $ postbreeding_migration_start &lt;date&gt; NA, 2019-08-10, NA, 2019-08-24, 2019-06-28, 2019-08-17, 2019-08-24, 2019-… #&gt; $ postbreeding_migration_end &lt;date&gt; NA, 2019-01-11, NA, 2019-11-23, 2019-10-19, 2019-12-21, 2019-12-07, 2019-… #&gt; $ prebreeding_migration_quality &lt;dbl&gt; 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3,… #&gt; $ prebreeding_migration_start &lt;date&gt; NA, 2019-03-08, NA, 2019-02-22, 2019-04-12, 2019-01-18, 2019-01-18, 2019-… #&gt; $ prebreeding_migration_end &lt;date&gt; NA, 2019-05-17, NA, 2019-05-03, 2019-05-17, 2019-05-31, 2019-05-31, 2019-… #&gt; $ resident_quality &lt;dbl&gt; 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3,… #&gt; $ resident_start &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2019-02-15, NA, 2… #&gt; $ resident_end &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2019-04-12, NA, 2… If you’re working in RStudio, you can use View() to interactively explore this data frame. You can also consult the Status and Trends landing page to see the full list of species. All species go through a process of expert human review prior to being released. The ebirdst_runs data frame also contains information from this review process. Reviewers assess each of the four seasons: breeding, non-breeding, pre-breeding migration, and post-breeding migration. Resident (i.e., non-migratory) species are identified by having TRUE in the resident column of ebirdst_runs, and these species are assessed across the whole year rather than seasonally. ebirdst_runs contains two important pieces of information for each season: a quality rating and seasonal dates. The seasonal dates define the weeks that fall within each season; these relative abundance estimates for these weeks get averaged to produce the seasonal relative abundance maps on the Status and Trends website. Breeding and non-breeding season dates are defined for each species as the weeks during those seasons when the species’ population does not move. For this reason, these seasons are also described as stationary periods. Migration periods are defined as the periods of movement between the stationary non-breeding and breeding seasons. Note that for many species these migratory periods include not only movement from breeding grounds to non-breeding grounds, but also post-breeding dispersal, molt migration, and other movements. Reviewers also examine the model estimates for each season to assess the amount of extrapolation or omission present in the model, and assign an associated quality rating ranging from 0 (lowest quality) to 3 (highest quality). Extrapolation refers to cases where the model predicts occurrence where the species is known to be absent, while omission refers to the model failing to predict occurrence where a species is known to be present. A rating of 0 implies this season failed review and model results should not be used at all for this period. Ratings of 1-3 correspond to a gradient of more to less extrapolation and/or omission, and we often use a traffic light analogy when referring to them: Red light: low quality, extensive extrapolation and/or omission and noise, but at least some regions have estimates that are accurate; can be used with caution in certain regions. Yellow light: medium quality, some extrapolation and/or omission; use with caution. Green light: high quality, very little or no extrapolation and/or omission; these seasons can be safely used. 1.5 Download data The function ebirdst_download() downloads data for a single species from AWS. All you need to do is provide the name (common name, scientific name, or species code) of the species you want to download. For this example, I’ll download the data for Loggerhead Shrike. sp_path &lt;- ebirdst_download(species = &quot;Loggerhead Shrike&quot;) sp_path #&gt; [1] &quot;/Users/mes335/Library/Application Support/ebirdst/logshr-ERD2019-STATUS-20201005-c29ce152&quot; The function will automatically identify a suitable location to store the downloaded data and return that path, which we captured in the variable sp_path. By default, ebirdst_download() downloads just the raster predictions from Status Data Products for relative occurrence, count, and abundance. We can see the files downloaded with: list.files(sp_path, recursive = TRUE) #&gt; [1] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance-seasonal_breeding.tif&quot; #&gt; [2] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance-seasonal_nonbreeding.tif&quot; #&gt; [3] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance-seasonal_postbreeding_migration.tif&quot; #&gt; [4] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance-seasonal_prebreeding_migration.tif&quot; #&gt; [5] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance-seasonal_breeding.tif&quot; #&gt; [6] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance-seasonal_nonbreeding.tif&quot; #&gt; [7] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance-seasonal_postbreeding_migration.tif&quot; #&gt; [8] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance-seasonal_prebreeding_migration.tif&quot; #&gt; [9] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance-seasonal_breeding.tif&quot; #&gt; [10] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance-seasonal_nonbreeding.tif&quot; #&gt; [11] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance-seasonal_postbreeding_migration.tif&quot; #&gt; [12] &quot;abundance_seasonal/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance-seasonal_prebreeding_migration.tif&quot; #&gt; [13] &quot;config.rds&quot; #&gt; [14] &quot;pi-pd.db&quot; #&gt; [15] &quot;predictions.db&quot; #&gt; [16] &quot;srd_raster_template.tif&quot; #&gt; [17] &quot;weekly_cubes/band_dates.csv&quot; #&gt; [18] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance_lower.tif&quot; #&gt; [19] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance_median.tif&quot; #&gt; [20] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance_upper.tif&quot; #&gt; [21] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_count_median.tif&quot; #&gt; [22] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_occurrence_median.tif&quot; #&gt; [23] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance_lower.tif&quot; #&gt; [24] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance_median.tif&quot; #&gt; [25] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_abundance_upper.tif&quot; #&gt; [26] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_count_median.tif&quot; #&gt; [27] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_lr_2019_occurrence_median.tif&quot; #&gt; [28] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance_lower.tif&quot; #&gt; [29] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance_median.tif&quot; #&gt; [30] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_abundance_upper.tif&quot; #&gt; [31] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_count_median.tif&quot; #&gt; [32] &quot;weekly_cubes/logshr-ERD2019-STATUS-20201005-c29ce152_mr_2019_occurrence_median.tif&quot; In addition to the raster data, the data packages contain two SQLite databases storing information about model performance and environmental associations. These files are quite large, and are not likely to be required by many users, so are not downloaded by default. Use tifs_only = FALSE to download this additional data: sp_path &lt;- ebirdst_download(species = &quot;logshr&quot;, tifs_only = FALSE) In the last lesson of this workshop we’ll touch on these non-raster Data Products. 1.6 Load data Now that we’ve downloaded the data package, let’s load some data into our R session. These are raster data (i.e. estimates are provided over a regular grid) and therefore we’ll need the raster package (loaded above) to work with them. There are a variety of layers available, but let’s load the relative abundance estimates. To learn about some of the other layers, consult the associated vignette from the ebirdst package. abd &lt;- load_raster(path = sp_path, product = &quot;abundance&quot;) abd #&gt; class : RasterStack #&gt; dimensions : 5630, 6957, 39167910, 52 (nrow, ncol, ncell, nlayers) #&gt; resolution : 2963, 2963 (x, y) #&gt; extent : -2e+07, 597137, -6673060, 1e+07 (xmin, xmax, ymin, ymax) #&gt; crs : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs #&gt; names : w2019.01.04, w2019.01.11, w2019.01.18, w2019.01.25, w2019.02.01, w2019.02.08, w2019.02.15, w2019.02.22, w2019.03.01, w2019.03.08, w2019.03.15, w2019.03.22, w2019.03.29, w2019.04.05, w2019.04.12, ... #&gt; min values : 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... #&gt; max values : 2.94, 3.07, 3.26, 3.36, 3.36, 3.46, 3.64, 3.53, 3.27, 3.25, 3.21, 3.68, 3.34, 2.24, 2.14, ... This is a RasterStack object with 52 layers, each providing a relative abundance estimate for a single week of the year. We typically refer to these are cubes, e.g. the relative abundance cubes refers to the full 52 week stack of relative abundance estimates. To see the dates corresponding to the midpoint of these weeks, use: parse_raster_dates(abd) #&gt; [1] &quot;2019-01-04&quot; &quot;2019-01-11&quot; &quot;2019-01-18&quot; &quot;2019-01-25&quot; &quot;2019-02-01&quot; &quot;2019-02-08&quot; &quot;2019-02-15&quot; &quot;2019-02-22&quot; #&gt; [9] &quot;2019-03-01&quot; &quot;2019-03-08&quot; &quot;2019-03-15&quot; &quot;2019-03-22&quot; &quot;2019-03-29&quot; &quot;2019-04-05&quot; &quot;2019-04-12&quot; &quot;2019-04-19&quot; #&gt; [17] &quot;2019-04-26&quot; &quot;2019-05-03&quot; &quot;2019-05-10&quot; &quot;2019-05-17&quot; &quot;2019-05-24&quot; &quot;2019-05-31&quot; &quot;2019-06-07&quot; &quot;2019-06-14&quot; #&gt; [25] &quot;2019-06-21&quot; &quot;2019-06-28&quot; &quot;2019-07-06&quot; &quot;2019-07-13&quot; &quot;2019-07-20&quot; &quot;2019-07-27&quot; &quot;2019-08-03&quot; &quot;2019-08-10&quot; #&gt; [33] &quot;2019-08-17&quot; &quot;2019-08-24&quot; &quot;2019-08-31&quot; &quot;2019-09-07&quot; &quot;2019-09-14&quot; &quot;2019-09-21&quot; &quot;2019-09-28&quot; &quot;2019-10-05&quot; #&gt; [41] &quot;2019-10-12&quot; &quot;2019-10-19&quot; &quot;2019-10-26&quot; &quot;2019-11-02&quot; &quot;2019-11-09&quot; &quot;2019-11-16&quot; &quot;2019-11-23&quot; &quot;2019-11-30&quot; #&gt; [49] &quot;2019-12-07&quot; &quot;2019-12-14&quot; &quot;2019-12-21&quot; &quot;2019-12-28&quot; For a given week, these data consist of estimates of relative abundance over a regular 2.96 km grid. For example, we can extract just the 20th week (centered on May 17, 2018) with: abd[[20]] #&gt; class : RasterLayer #&gt; band : 20 (of 52 bands) #&gt; dimensions : 5630, 6957, 39167910 (nrow, ncol, ncell) #&gt; resolution : 2963, 2963 (x, y) #&gt; extent : -2e+07, 597137, -6673060, 1e+07 (xmin, xmax, ymin, ymax) #&gt; crs : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs #&gt; source : logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance_median.tif #&gt; names : w2019.05.17 #&gt; values : 0, 2.13 (min, max) It can be computationally challenging to work with the full data cubes, so we’ve provided data at three resolutions. Depenending on the situation, you may want to consider using one of the lower resolutions: High resolution (hr): the native 2.96 km resolution data Medium resolution (mr): the hr data aggregated by a factor of 3 in each direction resulting in a resolution of 8.89 km Low resolution (lr): the hr data aggregated by a factor of 9 in each direction resulting in a resolution of 26.7 km To access the lower resolution data, use the resolution argument to load_raster(): abd_mr &lt;- load_raster(path = sp_path, product = &quot;abundance&quot;, resolution = &quot;mr&quot;) res(abd) #&gt; [1] 2963 2963 res(abd_mr) #&gt; [1] 8888 8888 1.7 Mapping Let’s map a quick map of the May 17 abundance data to see what it looks like. The function abundance_palette() gives us access to the color palettes used in the online versions of the maps. par(mar = c(0, 0, 0, 0)) plot(abd[[20]], axes = FALSE, box = FALSE, col = abundance_palette(100, season = &quot;weekly&quot;), maxpixels = ncell(abd)) Notice the extreme distortion in the continents, that most of this map is taken up by areas where the species doesn’t occur, and that there isn’t much resolution in the color palette in areas where it does occur. These raster layers are provided for the entire Western Hemisphere in a sinusoidal equal area projection. This format ensures consistency across the full set of Status and Trends species, but isn’t ideal for mapping the data for a single species. To address this, each Status and Trends data package comes with a set of parameters suitable for mapping the data for that species. Let’s reproduce the above map using the provided extent, projection, and legend bins. # load mapping parameters map_pars &lt;- load_fac_map_parameters(sp_path) # crop and reproject abundance raster abd_proj &lt;- abd[[20]] %&gt;% crop(map_pars$fa_extent_sinu) %&gt;% projectRaster(crs = map_pars$custom_projection, method = &quot;ngb&quot;) # map par(mar = c(0, 0, 0, 0)) pal &lt;- abundance_palette(length(map_pars$abundance_bins), season = &quot;weekly&quot;) plot(abd_proj, breaks = c(0, map_pars$abundance_bins), col = c(&quot;#e6e6e6&quot;, pal), axes = FALSE, box = FALSE, maxpixels = ncell(abd_proj)) Looking better, but still needs a lot of work! Consult the Introduction to Mapping vignette for additional tips on producing high-quality maps using these data. "],["site.html", "Lesson 2 Site Selection 2.1 Objective 2.2 Introduction 2.3 Seasonal abundance data 2.4 Range-wide site selection 2.5 Local Selection", " Lesson 2 Site Selection 2.1 Objective To use eBird Status Data Products to identify important sites for Loggerhead Shrike during the breeding season at different spatial scales. This is an example of an analysis you might do to prioritize sites for a species, perhaps for conservation or management. 2.2 Introduction In the previous lesson, we saw how to download and load weekly estimates of relative abundance into R for further analysis. In this lesson, we’ll demonstrate one possible use case for these data: identifying sites of high importance for a species of conservation concern. Let’s start by loading the libraries we’ll need for this analysis. library(ebirdst) library(raster) library(sf) library(rnaturalearth) library(dplyr) library(ggplot2) extract &lt;- raster::extract 2.3 Seasonal abundance data For this site selection analysis we’ll be interested in identifying important sites for Loggerhead Shrike during the breeding season. In the previous lesson we worked with weekly estimates of relative abundance and we saw that we can access predefined seasonal boundary dates from the ebirdst_runs data frame. logshr_run &lt;- filter(ebirdst_runs, common_name == &quot;Loggerhead Shrike&quot;) start_dt &lt;- logshr_run$breeding_start end_dt &lt;- logshr_run$breeding_end c(start_dt, end_dt) #&gt; [1] &quot;2019-05-24&quot; &quot;2019-07-20&quot; We could subset the weekly relative abundance RasterStack to just the breeding season weeks, then average across the weeks. However, as a shortcut, the data package provides pre-calculated seasonal raster layers, which we can access with load_raster(). # find the location of the data we downloaded in the previous lesson sp_path &lt;- get_species_path(&quot;Loggerhead Shrike&quot;) # load the seasonal rasters abd &lt;- load_raster(sp_path, &quot;abundance_seasonal&quot;) abd #&gt; class : RasterStack #&gt; dimensions : 5630, 6957, 39167910, 4 (nrow, ncol, ncell, nlayers) #&gt; resolution : 2963, 2963 (x, y) #&gt; extent : -2e+07, 597137, -6673060, 1e+07 (xmin, xmax, ymin, ymax) #&gt; crs : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs #&gt; names : breeding, postbreeding_migration, nonbreeding, prebreeding_migration # subset to just the breeding season abd_breeding &lt;- abd[[&quot;breeding&quot;]] abd_breeding #&gt; class : RasterLayer #&gt; dimensions : 5630, 6957, 39167910 (nrow, ncol, ncell) #&gt; resolution : 2963, 2963 (x, y) #&gt; extent : -2e+07, 597137, -6673060, 1e+07 (xmin, xmax, ymin, ymax) #&gt; crs : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs #&gt; source : logshr-ERD2019-STATUS-20201005-c29ce152_hr_2019_abundance-seasonal_breeding.tif #&gt; names : breeding This layer represents the expected relative abundance of Loggerhead Shrike during the breeding season on an eBird Traveling Count by a skilled eBirder starting at the optimal time of day with the optimal search duration and distance that maximizes detection of this species in a region. Let’s crop and re-project based on the species specific map parameters. # load mapping parameters map_pars &lt;- load_fac_map_parameters(sp_path) # crop and reproject abundance raster abd_breeding_proj &lt;- abd_breeding %&gt;% crop(map_pars$fa_extent_sinu) %&gt;% projectRaster(crs = map_pars$custom_projection, method = &quot;ngb&quot;) 2.4 Range-wide site selection To perform a range-wide site selection, we’ll identify the locations with the top 5% of non-zero abundance values across the entire range and visualize those locations. # remove zeroes prior to calculating quantiles abd_breeding_proj[abd_breeding_proj == 0] &lt;- NA # calculate the 95th quantile q95 &lt;- quantile(abd_breeding_proj, na.rm = TRUE, probs = 0.95) # identify top 5% of cells abd_top5 &lt;- trim(abd_breeding_proj &gt;= q95) Finally let’s map these selected sites. par(mar = c(0, 0, 0, 0)) plot(abd_top5, col = c(&#39;#d9d9d9&#39;, &#39;#fd8d3c&#39;), axes = FALSE, box = FALSE, maxpixels = ncell(abd_top5)) 2.5 Local Selection Let’s transition from broad-scale, region-wide site selection to a local site selection exercise. For example, let’s consider a land trust working in Louisiana trying to identify important sites for Loggerhead Shrike. To start, we’ll get a boundary polygon for Louisiana. # get spatial boundary for louisiana la &lt;- ne_states(iso_a2 = &quot;US&quot;, returnclass = &quot;sf&quot;) %&gt;% filter(name == &quot;Louisiana&quot;) %&gt;% # project st_transform(crs = map_pars$custom_projection) We can identify the quartiles of the abundance data within Louisiana, essentially dividing the cells within the state into four equally sized groups. # mask to louisiana abd_breeding_la &lt;- mask(abd_breeding_proj, la) %&gt;% raster::trim() # calculate abundance quartiles quarters &lt;- quantile(abd_breeding_la, probs = c(0.25, 0.5, 0.75, 1)) %&gt;% round(4) # map par(mar = c(1, 1, 1, 1)) plot(st_geometry(la)) plot(abd_breeding_la, breaks = c(0, quarters), col = abundance_palette(4, season = &quot;weekly&quot;), maxpixels = ncell(abd_breeding_la), box = FALSE, axes = FALSE, add = TRUE) plot(st_geometry(la), add = TRUE) 2.5.1 Uncertainty analysis When using these abundance rasters at a local scale, it’s important to be cautious because of the broad spatial scale at which the modeling was conducted. As with any modeled estimates, these abundance estimates have uncertainty associated with them. One approach to dealing with this is to use the spatial estimates of uncertainty (the 10th and 90th quantiles of relative abundance) to assess if locations that we’re considering for selection have overlapping confidence intervals. Let’s start by loading these upper and lower confidence interval raster layers, subsetting to the breeding season within Louisiana, and calculating a breeding season average. # load the upper and lower confidence intervals abd_upper &lt;- load_raster(sp_path, &quot;abundance_upper&quot;) abd_lower &lt;- load_raster(sp_path, &quot;abundance_lower&quot;) # subset to breeding season in louisiana la_breeding_season &lt;- ebirdst_extent(la, c(start_dt, end_dt)) abd_upper_br &lt;- ebirdst_subset(abd_upper, la_breeding_season) abd_lower_br &lt;- ebirdst_subset(abd_lower, la_breeding_season) # average for the breeding season and project abd_upper_br_avg &lt;- calc(abd_upper_br, fun = mean, na.rm = TRUE) %&gt;% projectRaster(crs = map_pars$custom_projection, method = &quot;ngb&quot;) abd_lower_br_avg &lt;- calc(abd_lower_br, fun = mean, na.rm = TRUE) %&gt;% projectRaster(crs = map_pars$custom_projection, method = &quot;ngb&quot;) Next, let’s imagine we’re considering three potential sites in northern Louisiana, one in each of the top three quartiles of abundance. # generate points and convert to spatial pts &lt;- data.frame(name = c(&quot;High&quot;, &quot;Middle&quot;, &quot;Low&quot;), lng = c(-91.173, -91.137, -91.169), lat = c(32.322, 32.271, 32.295)) %&gt;% st_as_sf(coords = c(&quot;lng&quot;, &quot;lat&quot;), crs = 4326) %&gt;% st_transform(crs = st_crs(map_pars$custom_projection)) pts$name &lt;- factor(pts$name, levels = c(&quot;High&quot;, &quot;Middle&quot;, &quot;Low&quot;)) We can overlay these points on a zoomed-in version of the above quartile map. Note that they each falls within a different colored cell, i.e. they all belong to different quartiles. plot(abd_breeding_la, breaks = c(0, quarters), col = abundance_palette(4, season = &quot;weekly&quot;), alpha = 0.75, ext = st_buffer(pts, 10000), maxpixels = ncell(abd_breeding_la), box = FALSE, axes = FALSE) plot(pts, pch = 21, bg = &quot;red&quot;, col = &quot;black&quot;, cex = 1, add = TRUE) Let’s look at the abundance and confidence intervals for each of these points. # extract raster values pts$abd &lt;- extract(abd_breeding_la, pts) pts$lower &lt;- extract(abd_lower_br_avg, pts) pts$upper &lt;- extract(abd_upper_br_avg, pts) # plot the confidence intervals for the three points ggplot(pts, aes(y = abd, x = name)) + geom_point() + geom_errorbar(aes(ymin = lower, ymax = upper)) + labs(x = &quot;Location&quot;, y = &quot;Relative Abundance&quot;, title = &quot;Confidence intervals for locations&quot;) So, despite the “High” and “Middle” sites belonging to different quartiles of relative abundance, the uncertainty analysis suggests that we don’t have good evidence to pick one site over the other. In contrast, the “Low” site is signficantly lower in relative abundance than the other two sites. 2.5.2 Ground truth One additional way to check the results of a site selection exercise is to ground truth the results using satellite imagery for the region in question. "],["trajectories.html", "Lesson 3 Multi-species Trajectories 3.1 Objective 3.2 Introduction 3.3 Multi-species data 3.4 Proportion of population 3.5 Trajectories 3.6 Richness", " Lesson 3 Multi-species Trajectories 3.1 Objective To prepare data for comparing Status and Trends results across multiple species. As an example, we’ll compute proportion of population trajectories for a suite of species. 3.2 Introduction Comparing Status Data Products between species requires extra caution because the models give relative rather than absolute abundance. For example, species differ in their detectability, and this may cause differences in relative abundance. To address this, we’ll convert relative abundance to a proportion of population metric for each species by dividing the abundance layer by the total abundance summed across the entire range. For any given cell, this gives the proportion of relative abundance occurring in that cell. In addition, in this lesson we’ll look at the temporal dimension of these data, plotting trajectories through time for a given region. Let’s start by loading the necessary packages for this lesson. library(ebirdst) library(raster) library(sf) library(rnaturalearth) library(tidyverse) library(parallel) extract &lt;- raster::extract For this example, we’ll be looking at a suite of shorebird species in Kansas, so let’s also get a boundary polygon for that state. ks &lt;- ne_states(iso_a2 = &quot;US&quot;, returnclass = &quot;sf&quot;) %&gt;% filter(name == &quot;Kansas&quot;) 3.3 Multi-species data We begin by downloading data for a suite of 7 shorebird species that all spend at least a portion of the year within Kansas. species &lt;- c(&quot;American Avocet&quot;, &quot;Snowy Plover&quot;, &quot;Hudsonian Godwit&quot;, &quot;Willet&quot;, &quot;Marbled Godwit&quot;, &quot;Sanderling&quot;, &quot;Semipalmated Sandpiper&quot;) sp_dirs &lt;- map_chr(species, ebirdst_download) %&gt;% setNames(species) 3.4 Proportion of population Our goal is to produce trajectories comparing the proportion of each species’ population within Kansas for each week of 2019. For each species we need to: Calculate the sum of the abundance within Kansas for each week Calculate the sum of the abundance across the entire range of the species for each week Calculate the proportion of the population as the ratio of the within Kansas abundance to the total abundance The below function performs these steps for a given species. Iterating over the full set of species at the highest resolution is quite computationally intensive, so to speed things up we’re using the low resolution relative abundance estimates. Note that even at the lower resolution, this will still take a few minutes to run. calculate_trajectory &lt;- function(x, common_name, region) { message(names(x)) # load and crop weekly abundance abd &lt;- load_raster(x, product = &quot;abundance&quot;, resolution = &quot;lr&quot;) r &lt;- st_transform(region, crs = st_crs(abd)) # total abundance within region abd_region &lt;- abd %&gt;% crop(r) %&gt;% extract(r, fun = sum) abd_region &lt;- abd_region[1, , drop = TRUE] # calculate total range-wide abundance if (.Platform$OS.type == &quot;unix&quot;) { abd_total &lt;- mclapply(seq.int(nlayers(abd)), function(i) cellStats(abd[[i]], sum), mc.preschedule = TRUE, mc.set.seed = TRUE, mc.cores = detectCores()) %&gt;% unlist() } else { abd_total &lt;- lapply(seq.int(nlayers(abd)), function(i) cellStats(abd[[i]], sum)) %&gt;% unlist() } data.frame(common_name = common_name, date = parse_raster_dates(abd), prop_pop = abd_region / abd_total, row.names = NULL) } trajectories &lt;- map2_dfr(sp_dirs, names(sp_dirs), calculate_trajectory, region = ks) write_csv(trajectories, &quot;data/shorebird_pop-trajectories.csv&quot;) 3.5 Trajectories Now we can plot these trajectories for the set of shorebird species. ggplot(trajectories, aes(date, prop_pop, color = common_name)) + geom_line() + labs(x = &quot;Week&quot;, y = &quot;Proportion of Population in Kansas&quot;, color = NULL) + theme(legend.position = &quot;bottom&quot;) 3.6 Richness Finally, we can combine these 7 trajectories into a single trajectory giving an estimate of the richness of this group of shorebirds throughout the year. richness &lt;- trajectories %&gt;% group_by(date) %&gt;% summarise(n_species = n_distinct(common_name[prop_pop != 0])) # plot richness ggplot(richness, aes(date, n_species)) + geom_line() + labs(x = &quot;Week&quot;, y = &quot;Richness&quot;) "],["nonraster.html", "Lesson 4 Non-raster Data 4.1 Objective 4.2 Introduction 4.3 Effective extent 4.4 Predictive performance metrics 4.5 Predictor importance 4.6 Partial dependance 4.7 Habitat association", " Lesson 4 Non-raster Data 4.1 Objective To use the non-raster data to examine habitat associations and as a diagnostic tool to assess predictive performance. 4.2 Introduction If we use ebirdst_download(tifs_only = FALSE), the data packages that get downloaded will contain two additional SQLite database that provide: Information about the modeled relationships between estimated occurrence and the ecological covariates used in the model in the form of predictor importance (PI) estimates and partial dependence (PD) relationships Information about the statistical performance of the models, which can be use to estimate a suite of predictive performance metrics (PPMs) These data are provided at the level of the individual stixels that make up the ensemble that produces the abundance estimates. Stixels are identified by their centroid in space and time, which allows for calculation of PIs, PDs, and PPMs within a specific region and season by summarizing across just those stixels whose centroids that fall within the given region and season. We’ll start by loading packages and defining a focal region and time period: Louisiana during the breeding season. library(ebirdst) library(raster) library(sf) library(rnaturalearth) library(dplyr) library(ggplot2) # louisiana la &lt;- ne_states(iso_a2 = &quot;US&quot;, returnclass = &quot;sf&quot;) %&gt;% filter(name == &quot;Louisiana&quot;) # breeding season logshr_run &lt;- filter(ebirdst_runs, common_name == &quot;Loggerhead Shrike&quot;) start_dt &lt;- logshr_run$breeding_start end_dt &lt;- logshr_run$breeding_end # ebirdst_extent object la_breeding &lt;- ebirdst_extent(la, c(start_dt, end_dt)) # loggerhead shrike data path sp_path &lt;- get_species_path(&quot;logshr&quot;) 4.3 Effective extent For a given region and time period, stixel_footprint() produces a raster showing the spatial footprint of all the stixels whose centroids of fall within the given region and hence contribute to the model estimates there. To visualize this footprint, use plot(). footprint &lt;- stixel_footprint(sp_path, la_breeding) plot(footprint) 4.4 Predictive performance metrics We can use ebirdst_ppms() to calculate predictive performance metrics (PPMs) within a given region and season, here Louisiana during the breeding season, then call plot() to visualize these PPMs ppms &lt;- ebirdst_ppms(sp_path, la_breeding) plot(ppms) 4.5 Predictor importance The stixel-level data can also be used to identify the most importance predictor variables in the model for a given region and season. # load predictor importance data pis &lt;- load_pis(sp_path) # plot the predictor importances for louisiana in the breeding season plot_pis(pis, ext = la_breeding, by_cover_class = TRUE, n_top_pred = 25) 4.6 Partial dependance We can also produce partial dependence plots that show the relationship between a given model covariate and the occurrence probability. Let’s start by loading the PD data within the given region and season. pds &lt;- load_pds(sp_path, ext = la_breeding) Smoothed partial dependence curves for a given predictor can be plotted using plot_pds(). Confidence intervals are estimated through a processing of subsampling and bootstrapping. This function returns the smoothed data and CIs and plots these data. For example, let’s look at the impact of checklist start time (expressed as the difference in hours from solar noon) on the probability of observing a species. # in the interest of speed, run with 5 bootstrap iterations # in practice, best to run with the default number of iterations (100) pd_smooth &lt;- plot_pds(pds, &quot;solar_noon_diff&quot;, ext = la_breeding, n_bs = 5) As you’d expect, early morning is the best time to observe Loggerhead shrike. We also have access to the data behind this smoothed PD curve. dplyr::glimpse(pd_smooth) #&gt; Rows: 25 #&gt; Columns: 4 #&gt; $ x &lt;dbl&gt; -11.9272, -10.9303, -9.9335, -8.9366, -7.9397, -6.9428, -5.9460, -4.9491, -3.9522, -2.9553, -1.… #&gt; $ pd_median &lt;dbl&gt; 8.42e-03, 8.35e-03, 7.33e-03, 8.24e-03, 8.56e-03, 8.93e-03, 7.45e-03, 5.14e-03, 2.88e-03, 9.07e… #&gt; $ pd_lower &lt;dbl&gt; 0.004907, 0.005326, 0.006127, 0.006603, 0.007228, 0.007768, 0.007055, 0.004898, 0.002337, -0.00… #&gt; $ pd_upper &lt;dbl&gt; 0.010101, 0.009306, 0.008928, 0.008586, 0.009114, 0.009606, 0.008104, 0.005532, 0.002993, 0.000… In addition to the effort covariates, we can also look at the relationships for the ecological covariates. For example, we saw from the PI plot that “dense herbaceous” is an important covariate, so let’s example the PD curve for that variable. We can find it, and all other model covariates, listed in the ebirdst_predictors data frame. ebirdst_predictors %&gt;% filter(lc_class_label == &quot;Dense Herbaceous&quot;) %&gt;% select(predictor_tidy, predictor_label) #&gt; # A tibble: 2 × 2 #&gt; predictor_tidy predictor_label #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 mcd12q1_lccs1_fs_c31_1500_ed Dense Herbaceous ED #&gt; 2 mcd12q1_lccs1_fs_c31_1500_pland Dense Herbaceous PLAND pd_smooth &lt;- plot_pds(pds, &quot;mcd12q1_lccs1_fs_c31_1500_pland&quot;, ext = la_breeding, n_bs = 5) So, Loggerhead Shrike has a strong positive association with dense herbaceous cover during the breeding season in Louisiana. 4.7 Habitat association Finally, the PI and PD information can be combined to produce habitat charts similar to those available on the eBird Status and Trends website. The charts visualize how species associate with different habitat types throughout the year, giving both the strength and direction of that association. habitat &lt;- ebirdst_habitat(sp_path, ext = la_breeding) plot(habitat) "],["aos21.html", "Lesson 5 AOS 2021 5.1 Objective 5.2 Percent of population 5.3 Habitat associations", " Lesson 5 AOS 2021 5.1 Objective Covering examples specifically requested at the AOS 2021 workshop. library(ebirdst) library(raster) library(sf) library(rnaturalearth) library(tidyverse) library(exactextractr) 5.2 Percent of population The abundance regional stats section of the status and trends website provides estimates of the percent of the population within each state or Bird Conservation Region (BCR). Users of the data may want to calculate this percent of population for custom regions, not found on the status and trends website. As an example, let’s calculate the percent of population found in US states during each season. Let’s start by downloading state boundaries from Natural Earth and loading the seasonal relative abundance. Here we’ll use the lr data in the interest of speed. # loggerhead shrike seasonal abundance abd &lt;- get_species_path(&quot;logshr&quot;) %&gt;% load_raster(&quot;abundance_seasonal&quot;, res = &quot;lr&quot;) # border of louisiana states &lt;- ne_states(iso_a2 = &quot;US&quot;, returnclass = &quot;sf&quot;) %&gt;% st_transform(crs = projection(abd)) Next we’ll convert the relative abundance raster into a percent of population raster by dividing by the total population across the whole range. abd_total &lt;- cellStats(abd, sum) pct_pop &lt;- abd / abd_total Finally, we can extract all the values that fall within the given polygon and sum them to calculate the percent of population within the polygon. state_pop &lt;- exact_extract(pct_pop, states, fun = &quot;sum&quot;, append_cols = &quot;name&quot;, progress = FALSE) arrange(state_pop, -sum.breeding) #&gt; name sum.breeding sum.postbreeding_migration sum.nonbreeding sum.prebreeding_migration #&gt; 1 California 9.11e-02 6.55e-02 6.95e-02 7.67e-02 #&gt; 2 Arizona 8.51e-02 7.44e-02 5.98e-02 6.17e-02 #&gt; 3 Texas 6.21e-02 1.79e-01 2.16e-01 1.68e-01 #&gt; 4 Nevada 5.68e-02 3.29e-02 2.11e-02 3.77e-02 #&gt; 5 New Mexico 5.52e-02 6.48e-02 5.92e-02 6.18e-02 #&gt; 6 Montana 3.91e-02 1.05e-02 0.00e+00 1.05e-02 #&gt; 7 Wyoming 3.37e-02 1.12e-02 0.00e+00 1.01e-02 #&gt; 8 Utah 3.29e-02 1.01e-02 5.53e-03 1.55e-02 #&gt; 9 Florida 2.80e-02 2.56e-02 2.84e-02 2.73e-02 #&gt; 10 Colorado 2.73e-02 2.25e-02 5.16e-03 2.57e-02 #&gt; 11 Louisiana 2.50e-02 1.63e-02 2.34e-02 1.99e-02 #&gt; 12 Idaho 1.85e-02 4.78e-03 9.04e-05 4.45e-03 #&gt; 13 South Dakota 1.52e-02 5.61e-03 0.00e+00 4.78e-03 #&gt; 14 Oregon 1.32e-02 7.10e-03 1.16e-04 6.14e-03 #&gt; 15 Kansas 1.10e-02 1.14e-02 6.47e-03 1.78e-02 #&gt; 16 Nebraska 1.07e-02 6.92e-03 1.48e-07 8.07e-03 #&gt; 17 Oklahoma 7.90e-03 1.61e-02 2.00e-02 1.83e-02 #&gt; 18 North Dakota 6.11e-03 1.73e-03 0.00e+00 2.18e-03 #&gt; 19 Arkansas 6.06e-03 5.25e-03 7.98e-03 7.32e-03 #&gt; 20 Georgia 5.94e-03 5.02e-03 6.48e-03 7.14e-03 #&gt; 21 Mississippi 5.79e-03 4.20e-03 6.51e-03 6.26e-03 #&gt; 22 Missouri 3.98e-03 1.98e-03 2.26e-03 2.43e-03 #&gt; 23 Washington 2.53e-03 4.72e-04 0.00e+00 1.42e-03 #&gt; 24 Alabama 2.11e-03 1.32e-03 1.70e-03 2.07e-03 #&gt; 25 North Carolina 1.76e-03 1.46e-03 1.69e-03 2.22e-03 #&gt; 26 Iowa 1.68e-03 5.64e-05 0.00e+00 1.43e-05 #&gt; 27 South Carolina 1.63e-03 1.72e-03 2.34e-03 1.52e-03 #&gt; 28 Tennessee 1.15e-03 5.34e-04 7.07e-04 8.69e-04 #&gt; 29 Illinois 1.97e-04 2.99e-06 9.20e-06 9.88e-05 #&gt; 30 Indiana 1.04e-04 1.62e-08 1.18e-06 1.67e-05 #&gt; 31 Kentucky 9.55e-05 8.07e-05 2.23e-04 1.93e-04 #&gt; 32 Minnesota 5.91e-05 7.41e-06 0.00e+00 1.14e-05 #&gt; 33 Virginia 4.70e-05 1.32e-05 3.50e-05 4.48e-05 #&gt; 34 Michigan 4.41e-06 0.00e+00 0.00e+00 2.66e-07 #&gt; 35 West Virginia 1.75e-06 2.95e-07 2.24e-06 2.81e-06 #&gt; 36 Wisconsin 1.73e-06 2.63e-07 0.00e+00 4.20e-07 #&gt; 37 Maryland 7.47e-07 2.06e-07 1.03e-06 4.77e-07 #&gt; 38 Pennsylvania 5.54e-07 1.01e-07 5.23e-07 5.51e-08 #&gt; 39 New York 2.29e-07 3.24e-08 2.64e-10 2.08e-07 #&gt; 40 Ohio 4.05e-08 0.00e+00 3.16e-07 4.57e-07 #&gt; 41 Maine 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 42 New Hampshire 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 43 Vermont 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 44 Alaska 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 45 District of Columbia 0.00e+00 1.33e-08 0.00e+00 0.00e+00 #&gt; 46 Delaware 0.00e+00 2.85e-08 3.22e-07 0.00e+00 #&gt; 47 New Jersey 0.00e+00 1.59e-07 8.07e-10 0.00e+00 #&gt; 48 Connecticut 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 49 Rhode Island 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 50 Massachusetts 0.00e+00 0.00e+00 0.00e+00 0.00e+00 #&gt; 51 Hawaii 0.00e+00 0.00e+00 0.00e+00 0.00e+00 5.3 Habitat associations As covered in lesson 4 on non-raster data, the data packages contain two types of information about the the modeled relationships between estimated occurrence and the habitat covariates used in the model. Predictor importance (PI) estimates identify the most importance predictor variables in the model. Partial dependences (PD) show the relationship between a given habitat covariate and the occurrence probability. Let’s start by defining a region and season: Loggerhead Shrike within Louisiana during the breeding season. # loggerhead shrike data path sp_path &lt;- get_species_path(&quot;logshr&quot;) # border of louisiana la &lt;- ne_states(iso_a2 = &quot;US&quot;, returnclass = &quot;sf&quot;) %&gt;% filter(name == &quot;Louisiana&quot;) # breeding season logshr_run &lt;- filter(ebirdst_runs, common_name == &quot;Loggerhead Shrike&quot;) start_dt &lt;- logshr_run$breeding_start end_dt &lt;- logshr_run$breeding_end # ebirdst_extent object la_breeding &lt;- ebirdst_extent(la, c(start_dt, end_dt)) Now we can look at the most important predictors: pis &lt;- load_pis(sp_path, ext = la_breeding) plot_pis(pis, ext = la_breeding, by_cover_class = TRUE, n_top_pred = 25) From this PI plot we can see that “dense herbaceous” is an important covariate, so let’s example the PD curve for that habitat type. We can find it, and all other model covariates, listed in the ebirdst_predictors data frame. pds &lt;- load_pds(sp_path, ext = la_breeding) ebirdst_predictors %&gt;% filter(lc_class_label == &quot;Dense Herbaceous&quot;) %&gt;% select(predictor_tidy, predictor_label) #&gt; # A tibble: 2 × 2 #&gt; predictor_tidy predictor_label #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 mcd12q1_lccs1_fs_c31_1500_ed Dense Herbaceous ED #&gt; 2 mcd12q1_lccs1_fs_c31_1500_pland Dense Herbaceous PLAND pd_smooth &lt;- plot_pds(pds, &quot;mcd12q1_lccs1_fs_c31_1500_pland&quot;, ext = la_breeding, n_bs = 5) We can think of the PIs and PDs telling us something about the strength and directionality of a habitat association, respectively. For example, there is a strong positive association with dense herbaceous cover. The regional habitat charts on the eBird Status and Trends website combine the PI and PD information to visualize how species associate with different habitat types throughout the year, giving both the strength and direction of that association. The function ebirdst_habitat() generates the data behind these plots for a given region. habitat &lt;- ebirdst_habitat(sp_path, ext = la_breeding) habitat #&gt; # A tibble: 1,248 × 5 #&gt; predictor date importance prob_pos_slope direction #&gt; * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 intertidal_fs_c1_1500_pland 0.0096 0.00423 0.308 NA #&gt; 2 intertidal_fs_c1_1500_pland 0.0288 0.00428 0.307 NA #&gt; 3 intertidal_fs_c1_1500_pland 0.0481 0.00433 0.308 NA #&gt; 4 intertidal_fs_c1_1500_pland 0.0673 0.00438 0.308 NA #&gt; 5 intertidal_fs_c1_1500_pland 0.0865 0.00444 0.308 NA #&gt; 6 intertidal_fs_c1_1500_pland 0.106 0.00451 0.308 NA #&gt; # … with 1,242 more rows We can call plot() on the output of ebirdst_habitat() to generate a habitat association chart. plot(habitat) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
